{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bcfa10c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1aadf823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.jpg: (28, 28)\n",
      "22.jpg: (28, 28)\n",
      "27.jpg: (28, 28)\n",
      "89.jpg: (28, 28)\n",
      "21.jpg: (28, 28)\n",
      "42.jpg: (28, 28)\n",
      "60.jpg: (28, 28)\n",
      "24.jpg: (28, 28)\n",
      "45.jpg: (28, 28)\n",
      "35.jpg: (28, 28)\n",
      "9.jpg: (28, 28)\n",
      "95.jpg: (28, 28)\n",
      "0.jpg: (28, 28)\n",
      "66.jpg: (28, 28)\n",
      "81.jpg: (28, 28)\n",
      "92.jpg: (28, 28)\n",
      "96.jpg: (28, 28)\n",
      "94.jpg: (28, 28)\n",
      "62.jpg: (28, 28)\n",
      "12.jpg: (28, 28)\n",
      "69.jpg: (28, 28)\n",
      "54.jpg: (28, 28)\n",
      "25.jpg: (28, 28)\n",
      "39.jpg: (28, 28)\n",
      "2.jpg: (28, 28)\n",
      "63.jpg: (28, 28)\n",
      "32.jpg: (28, 28)\n",
      "90.jpg: (28, 28)\n",
      "43.jpg: (28, 28)\n",
      "11.jpg: (28, 28)\n",
      "4.jpg: (28, 28)\n",
      "6.jpg: (28, 28)\n",
      "31.jpg: (28, 28)\n",
      "59.jpg: (28, 28)\n",
      "56.jpg: (28, 28)\n",
      "23.jpg: (28, 28)\n",
      "99.jpg: (28, 28)\n",
      "17.jpg: (28, 28)\n",
      "72.jpg: (28, 28)\n",
      "84.jpg: (28, 28)\n",
      "52.jpg: (28, 28)\n",
      "33.jpg: (28, 28)\n",
      "34.jpg: (28, 28)\n",
      "65.jpg: (28, 28)\n",
      "48.jpg: (28, 28)\n",
      "51.jpg: (28, 28)\n",
      "15.jpg: (28, 28)\n",
      "80.jpg: (28, 28)\n",
      "44.jpg: (28, 28)\n",
      "13.jpg: (28, 28)\n",
      "29.jpg: (28, 28)\n",
      "10.jpg: (28, 28)\n",
      "1.jpg: (28, 28)\n",
      "16.jpg: (28, 28)\n",
      "49.jpg: (28, 28)\n",
      "47.jpg: (28, 28)\n",
      "30.jpg: (28, 28)\n",
      "73.jpg: (28, 28)\n",
      "82.jpg: (28, 28)\n",
      "64.jpg: (28, 28)\n",
      "91.jpg: (28, 28)\n",
      "40.jpg: (28, 28)\n",
      "19.jpg: (28, 28)\n",
      "28.jpg: (28, 28)\n",
      "87.jpg: (28, 28)\n",
      "93.jpg: (28, 28)\n",
      "41.jpg: (28, 28)\n",
      "8.jpg: (28, 28)\n",
      "14.jpg: (28, 28)\n",
      "97.jpg: (28, 28)\n",
      "88.jpg: (28, 28)\n",
      "7.jpg: (28, 28)\n",
      "5.jpg: (28, 28)\n",
      "68.jpg: (28, 28)\n",
      "20.jpg: (28, 28)\n",
      "67.jpg: (28, 28)\n",
      "70.jpg: (28, 28)\n",
      "75.jpg: (28, 28)\n",
      "77.jpg: (28, 28)\n",
      "26.jpg: (28, 28)\n",
      "3.jpg: (28, 28)\n",
      "18.jpg: (28, 28)\n",
      "58.jpg: (28, 28)\n",
      "98.jpg: (28, 28)\n",
      "46.jpg: (28, 28)\n",
      "38.jpg: (28, 28)\n",
      "76.jpg: (28, 28)\n",
      "74.jpg: (28, 28)\n",
      "36.jpg: (28, 28)\n",
      "50.jpg: (28, 28)\n",
      "78.jpg: (28, 28)\n",
      "85.jpg: (28, 28)\n",
      "53.jpg: (28, 28)\n",
      "83.jpg: (28, 28)\n",
      "57.jpg: (28, 28)\n",
      "61.jpg: (28, 28)\n",
      "79.jpg: (28, 28)\n",
      "55.jpg: (28, 28)\n",
      "86.jpg: (28, 28)\n",
      "71.jpg: (28, 28)\n",
      "\n",
      "üìå Ï†ÑÏ≤¥ Ïù¥ÎØ∏ÏßÄ Í≥†Ïú† ÌÅ¨Í∏∞ Î™©Î°ù: {(28, 28)}\n",
      "‚û° Î™®Îì† Ïù¥ÎØ∏ÏßÄÍ∞Ä ÎèôÏùºÌïú ÌÅ¨Í∏∞ (28, 28) Î•º Í∞ÄÏßëÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "# Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ ÌôïÏù∏\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Ïù¥ÎØ∏ÏßÄÍ∞Ä Îì§Ïñ¥ ÏûàÎäî Ìè¥Îçî Í≤ΩÎ°ú\n",
    "folder_path = os.path.expanduser('~/aiffel/rock_scissor_paper/paper')\n",
    "\n",
    "# Ìè¥Îçî ÎÇ¥ Ïù¥ÎØ∏ÏßÄ ÌååÏùº Î™©Î°ù\n",
    "image_files = [f for f in os.listdir(folder_path) \n",
    "               if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "sizes = set()\n",
    "\n",
    "for img_name in image_files:\n",
    "    img_path = os.path.join(folder_path, img_name)\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ (width, height)\n",
    "    size = img.size\n",
    "    sizes.add(size)   \n",
    "    print(f\"{img_name}: {size}\")\n",
    "\n",
    "print(\"\\nüìå Ï†ÑÏ≤¥ Ïù¥ÎØ∏ÏßÄ Í≥†Ïú† ÌÅ¨Í∏∞ Î™©Î°ù:\", sizes)\n",
    "\n",
    "# ÎßåÏïΩ ÌÅ¨Í∏∞Í∞Ä ÌïòÎÇòÎßå ÏûàÎã§Î©¥ ‚Üí Î™®Îì† Ïù¥ÎØ∏ÏßÄÍ∞Ä ÎèôÏùº ÌÅ¨Í∏∞\n",
    "if len(sizes) == 1:\n",
    "    print(f\"‚û° Î™®Îì† Ïù¥ÎØ∏ÏßÄÍ∞Ä ÎèôÏùºÌïú ÌÅ¨Í∏∞ {sizes.pop()} Î•º Í∞ÄÏßëÎãàÎã§.\")\n",
    "else:\n",
    "    print(\"‚ö† Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Í∞Ä ÏÑúÎ°ú Îã§Î¶ÖÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95dd0a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL ÎùºÏù¥Î∏åÎü¨Î¶¨ import ÏôÑÎ£å!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "Í∞ÄÏúÑ Ïù¥ÎØ∏ÏßÄ resize ÏôÑÎ£å!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "Î∞îÏúÑ Ïù¥ÎØ∏ÏßÄ resize ÏôÑÎ£å!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "Î≥¥ Ïù¥ÎØ∏ÏßÄ resize ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞ + Resize ÌïòÍ∏∞\n",
    "from PIL import Image \n",
    "import glob\n",
    "import os\n",
    "print(\"PIL ÎùºÏù¥Î∏åÎü¨Î¶¨ import ÏôÑÎ£å!\")\n",
    "\n",
    "\n",
    "# 1) ‚≠êÍ∞ÄÏúÑ Ïù¥ÎØ∏ÏßÄÎ•º Î∂àÎü¨ÏôÄÏÑú 28x28 ÏÇ¨Ïù¥Ï¶àÎ°ú Î≥ÄÍ≤Ω\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")     \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # ÌååÏùºÎßàÎã§ Î™®Îëê 28x28 ÏÇ¨Ïù¥Ï¶àÎ°ú Î∞îÍæ∏Ïñ¥ Ï†ÄÏû•Ìï©ÎãàÎã§.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")   \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# Í∞ÄÏúÑ Ïù¥ÎØ∏ÏßÄÍ∞Ä Ï†ÄÏû•Îêú ÎîîÎ†âÌÜ†Î¶¨ ÏïÑÎûòÏùò Î™®Îì† jpg ÌååÏùºÏùÑ ÏùΩÏñ¥Îì§Ïó¨ÏÑú\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"Í∞ÄÏúÑ Ïù¥ÎØ∏ÏßÄ resize ÏôÑÎ£å!\")\n",
    "\n",
    "\n",
    "# 2) ‚≠êÎ∞îÏúÑ Ïù¥ÎØ∏ÏßÄÎ•º Î∂àÎü¨ÏôÄÏÑú 28x28 ÏÇ¨Ïù¥Ï¶àÎ°ú Î≥ÄÍ≤Ω\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"Î∞îÏúÑ Ïù¥ÎØ∏ÏßÄ resize ÏôÑÎ£å!\")\n",
    "\n",
    "\n",
    "# 3) ‚≠êÎ≥¥ Ïù¥ÎØ∏ÏßÄÎ•º Î∂àÎü¨ÏôÄÏÑú 28x28 ÏÇ¨Ïù¥Ï¶àÎ°ú Î≥ÄÍ≤Ω\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"Î≥¥ Ïù¥ÎØ∏ÏßÄ resize ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "977db3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµÎç∞Ïù¥ÌÑ∞(x_train)Ïùò Ïù¥ÎØ∏ÏßÄ Í∞úÏàòÎäî 300 ÏûÖÎãàÎã§.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# Í∞ÄÏúÑ, Î∞îÏúÑ, Î≥¥ Îç∞Ïù¥ÌÑ∞Î•º ÏùΩÏùÑ Ïàò ÏûàÎäî load_data() Ìï®Ïàò ÏÉùÏÑ±\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # Í∞ÄÏúÑÎ∞îÏúÑÎ≥¥ Ïù¥ÎØ∏ÏßÄ Í∞úÏàò Ï¥ùÌï©Ïóê Ï£ºÏùòÌïòÏÑ∏Ïöî.\n",
    "    # Í∞ÄÏúÑ : 0, Î∞îÏúÑ : 1, Î≥¥ : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞ÏôÄ ÎùºÎ≤®(Í∞ÄÏúÑ : 0, Î∞îÏúÑ : 1, Î≥¥ : 2) Îç∞Ïù¥ÌÑ∞Î•º Îã¥ÏùÑ ÌñâÎ†¨(matrix) ÏòÅÏó≠ÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # Îç∞Ïù¥ÌÑ∞ ÏòÅÏó≠Ïóê Ïù¥ÎØ∏ÏßÄ ÌñâÎ†¨ÏùÑ Î≥µÏÇ¨\n",
    "        labels[idx]=0   # Í∞ÄÏúÑ : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # Îç∞Ïù¥ÌÑ∞ ÏòÅÏó≠Ïóê Ïù¥ÎØ∏ÏßÄ ÌñâÎ†¨ÏùÑ Î≥µÏÇ¨\n",
    "        labels[idx]=1   # Î∞îÏúÑ : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # Îç∞Ïù¥ÌÑ∞ ÏòÅÏó≠Ïóê Ïù¥ÎØ∏ÏßÄ ÌñâÎ†¨ÏùÑ Î≥µÏÇ¨\n",
    "        labels[idx]=2   # Î≥¥ : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"ÌïôÏäµÎç∞Ïù¥ÌÑ∞(x_train)Ïùò Ïù¥ÎØ∏ÏßÄ Í∞úÏàòÎäî\", idx,\"ÏûÖÎãàÎã§.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # ÏûÖÎ†•ÏùÄ 0~1 ÏÇ¨Ïù¥Ïùò Í∞íÏúºÎ°ú Ï†ïÍ∑úÌôî\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05f06223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÎùºÎ≤®:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ïù¥ÎØ∏ÏßÄ Î∂àÎü¨Ïò§Í∏∞\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('ÎùºÎ≤®: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df82db89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_60 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Í∞ÄÏúÑÎ∞îÏúÑÎ≥¥Î•º Ïù∏ÏãùÌïòÎäî Îî•Îü¨Îãù ÎÑ§Ìä∏ÏõåÌÅ¨ ÏÑ§Í≥Ñ\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏòàÏãú\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "112fd2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 37ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.0126 - accuracy: 0.9967\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 49ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0195 - accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.0221 - accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "10/10 - 0s - loss: 4.2823 - accuracy: 0.6267\n",
      "train_loss: 4.282339572906494\n",
      "train_accuracy: 0.6266666650772095\n"
     ]
    }
   ],
   "source": [
    "# Îî•Îü¨Îãù ÎÑ§Ìä∏ÏõåÌÅ¨ ÌïôÏäµÏãúÌÇ§Í∏∞\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Î™®Îç∏ ÌõàÎ†®\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "train_loss, train_accuracy = model.evaluate(x_train_norm, y_train, verbose=2)\n",
    "print(f\"train_loss: {train_loss}\")\n",
    "print(f\"train_accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "519d1a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "ÌïôÏäµÎç∞Ïù¥ÌÑ∞(x_train)Ïùò Ïù¥ÎØ∏ÏßÄ Í∞úÏàòÎäî 300 ÏûÖÎãàÎã§.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÎßåÎì§Í∏∞\n",
    "# x_test, y_testÎ•º ÎßåÎìúÎäî Î∞©Î≤ïÏùÄ x_train, y_trainÏùÑ ÎßåÎìúÎäî Î∞©Î≤ïÍ≥º ÏïÑÏ£º Ïú†ÏÇ¨Ìï©ÎãàÎã§.\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # ÏûÖÎ†•ÏùÄ 0~1 ÏÇ¨Ïù¥Ïùò Í∞íÏúºÎ°ú Ï†ïÍ∑úÌôî\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9fe3addf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 7.8727 - accuracy: 0.3667\n",
      "test_loss: 7.872679233551025 \n",
      "test_accuracy: 0.36666667461395264\n"
     ]
    }
   ],
   "source": [
    "# ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Î°ú ÌïòÏó¨ test accuracyÎ•º Ï∏°Ï†ï\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bc466a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_76 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 224,707\n",
      "Trainable params: 224,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 37ms/step - loss: 25.8954 - accuracy: 0.3100\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 3.1782 - accuracy: 0.3800\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 1.0380 - accuracy: 0.4633\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.9138 - accuracy: 0.5467\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.6603 - accuracy: 0.7433\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.5547 - accuracy: 0.7767\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.4582 - accuracy: 0.8500\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3904 - accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.3340 - accuracy: 0.9033\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.2982 - accuracy: 0.9200\n",
      "10/10 - 0s - loss: 3.0121 - accuracy: 0.4400\n",
      "test_loss: 3.01214337348938 \n",
      "test_accuracy: 0.4399999976158142\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "model = models.Sequential()\n",
    "\n",
    "# Î∞îÍøî Î≥º Ïàò ÏûàÎäî ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞Îì§\n",
    "n_channel_1=32         #16->32\n",
    "n_channel_2=64         #32->64\n",
    "n_dense=128             #32->128\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "# model.add(layers.BatchNormalization())     #BatchNormalization Ï†ÅÏö© (ÌïôÏäµ ÏïàÏ†ïÌôî)\n",
    "# model.add(layers.Dropout(0.5))             #Dropout Ï†ÅÏö© (Í≥ºÏ†ÅÌï© Î∞©ÏßÄ)\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Î™®Îç∏ ÌõàÎ†®\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# Î™®Îç∏ ÏãúÌóò\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9ced2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
