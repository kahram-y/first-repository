{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/cVyVdDpYA7jEHZScAezH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kahram-y/first-repository/blob/master/AML_project/AML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas networkx torch torch-geometric matplotlib pyvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR6Gi8_-UgVc",
        "outputId": "f2777ff4-0c67-430b-d356-c984258c5d65"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pyvis in /usr/local/lib/python3.12/dist-packages (0.3.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from pyvis) (4.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "# 1. 데이터 로드\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 파일 경로\n",
        "trans_path = '/content/drive/MyDrive/HI-Medium_Trans.csv'\n",
        "accounts_path = '/content/drive/MyDrive/HI-Medium_accounts.csv'\n",
        "\n",
        "# pandas 옵션 (컬럼 전체 표시)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# CSV 로드\n",
        "df = pd.read_csv(trans_path)\n",
        "acc_df = pd.read_csv(accounts_path)\n",
        "\n",
        "# 실습을 위해 데이터 샘플링 (전체 데이터가 매우 큼)\n",
        "df = df.head(50000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeOEaFcOVYsL",
        "outputId": "d3823bbd-bca4-400a-de6d-0dfc124e099e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdz5VMMIwCmR",
        "outputId": "50476ef8-f389-449f-e31a-3a88590cafb0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "0  2022/09/01 00:17         20  800104D70       20  800104D70   \n",
            "1  2022/09/01 00:02       3196  800107150     3196  800107150   \n",
            "2  2022/09/01 00:17       1208  80010E430     1208  80010E430   \n",
            "3  2022/09/01 00:03       1208  80010E650       20  80010E6F0   \n",
            "4  2022/09/01 00:02       1208  80010E650       20  80010EA30   \n",
            "\n",
            "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "0          6794.63          US Dollar      6794.63        US Dollar   \n",
            "1          7739.29          US Dollar      7739.29        US Dollar   \n",
            "2          1880.23          US Dollar      1880.23        US Dollar   \n",
            "3      73966883.00          US Dollar  73966883.00        US Dollar   \n",
            "4      45868454.00          US Dollar  45868454.00        US Dollar   \n",
            "\n",
            "  Payment Format  Is Laundering  \n",
            "0   Reinvestment              0  \n",
            "1   Reinvestment              0  \n",
            "2   Reinvestment              0  \n",
            "3         Cheque              0  \n",
            "4         Cheque              0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFqTpD72wP8D",
        "outputId": "90c82247-6c10-44cb-f502-d3cb6d6cf3ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Bank Name  Bank ID Account Number    Entity ID  \\\n",
            "0         China Bank #561    53267      817D00980  2AA1F24F180   \n",
            "1       Spain Bank #18657   316997      808BB2280  2AA1EEB8540   \n",
            "2    First Bank of Helena   339367      8505ED380  2AA206D7790   \n",
            "3       Mexico Bank #3367  3148419      8363D4180  2AA2001B1A0   \n",
            "4  Switzerland Bank #2372  3174937      842090C80  2AA20224CB0   \n",
            "\n",
            "                   Entity Name  \n",
            "0          Corporation #183669  \n",
            "1          Partnership #193780  \n",
            "2    Sole Proprietorship #4078  \n",
            "3          Partnership #133577  \n",
            "4  Sole Proprietorship #190823  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**그래프 생성 및 특징 추출 (Dual-view)**\n",
        "\n",
        "NetworkX를 사용하여 계좌 간 연결망을 구축하고, 금융결제원 자료에서 강조한 중심성(Centrality) 지표를 추출하여 기존 피처와 결합합니다."
      ],
      "metadata": {
        "id": "CZVkDMx6UcJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 그래프 생성 (NetworkX)\n",
        "G = nx.from_pandas_edgelist(df, source='Account', target='Account.1',\n",
        "                             edge_attr=['Amount Paid', 'Payment Currency', 'Is Laundering'],\n",
        "                             create_using=nx.DiGraph())\n",
        "\n",
        "# 3. 특징 추출 (Graph Feature) - 중심성 지표 계산\n",
        "print(\"계좌별 중심성 지표 계산 중...\")\n",
        "degree_cent = nx.degree_centrality(G)\n",
        "pagerank = nx.pagerank(G, alpha=0.85)\n",
        "\n",
        "# Dual-view 구성을 위한 데이터프레임 병합\n",
        "# 계좌(Node) 리스트를 기준으로 피처 테이블 생성\n",
        "nodes = list(G.nodes())\n",
        "feature_df = pd.DataFrame(nodes, columns=['Account'])\n",
        "feature_df['Degree_Cent'] = feature_df['Account'].map(degree_cent)\n",
        "feature_df['PageRank'] = feature_df['Account'].map(pagerank)\n",
        "\n",
        "# 결측값 처리\n",
        "feature_df.fillna(0, inplace=True)\n",
        "print(\"Graph Feature 추출 완료 (Dual-view 준비됨)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyD7id4oT06g",
        "outputId": "61f19377-68d5-455b-edea-1aa0caddcdac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "계좌별 중심성 지표 계산 중...\n",
            "Graph Feature 추출 완료 (Dual-view 준비됨)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 학습 (PyTorch Geometric - GraphSAGE)**\n",
        "\n",
        "추출된 특징을 바탕으로 GraphSAGE 알고리즘을 설계하여 학습을 진행합니다."
      ],
      "metadata": {
        "id": "Ns9_PGR6UElW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "# PyG 데이터 객체로 변환\n",
        "node_map = {node: i for i, node in enumerate(nodes)}\n",
        "edge_index = torch.tensor([[node_map[s], node_map[t]] for s, t in zip(df['Account'], df['Account.1'])], dtype=torch.long).t()\n",
        "\n",
        "# 노드 피처 (Dual-view: 여기서는 간단히 중심성 지표만 사용)\n",
        "x = torch.tensor(feature_df[['Degree_Cent', 'PageRank']].values, dtype=torch.float)\n",
        "\n",
        "# 라벨 생성 (거래 데이터의 Is Laundering을 노드 라벨로 변환 - 실습용 간략화)\n",
        "# 실제로는 계좌 자체가 사기인지 여부를 라벨링해야 함\n",
        "y = torch.zeros(len(nodes), dtype=torch.long)\n",
        "\n",
        "data = Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "# GraphSAGE 모델 설계\n",
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = SAGE(in_channels=2, hidden_channels=16, out_channels=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 학습 루프\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    # 실제 라벨이 있을 경우 Loss 계산 (예시 코드는 학습 구조만 제시)\n",
        "    # loss = F.cross_entropy(out, data.y)\n",
        "    # loss.backward()\n",
        "    # optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}: 학습 진행 중...\")\n",
        "\n",
        "print(\"GraphSAGE 모델 학습 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D6S8VWET00b",
        "outputId": "c3b38610-75bf-48f3-a956-3300993d5098"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: 학습 진행 중...\n",
            "Epoch 20: 학습 진행 중...\n",
            "Epoch 40: 학습 진행 중...\n",
            "Epoch 60: 학습 진행 중...\n",
            "Epoch 80: 학습 진행 중...\n",
            "GraphSAGE 모델 학습 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**시각화 (PyVis)**\n",
        "\n",
        "탐지된 의심스러운 자금 흐름망을 인터랙티브한 그래프로 시각화합니다."
      ],
      "metadata": {
        "id": "p5etIWzNUnAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvis.network import Network\n",
        "\n",
        "# 시각화를 위해 소규모 서브그래프 추출 (의심 거래 위주)\n",
        "suspicious_edges = df[df['Is Laundering'] == 1].head(100)\n",
        "subG = nx.from_pandas_edgelist(suspicious_edges, source='Account', target='Account.1',\n",
        "                                edge_attr=True, create_using=nx.DiGraph())\n",
        "\n",
        "# PyVis 시각화 설정\n",
        "net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", directed=True)\n",
        "\n",
        "for n in subG.nodes():\n",
        "    net.add_node(n, label=str(n), color='red' if n in suspicious_edges['Account'].values else 'blue')\n",
        "\n",
        "for e in subG.edges(data=True):\n",
        "    net.add_edge(e[0], e[1], title=f\"Amount Paid: {e[2]['Amount Paid']}\")\n",
        "\n",
        "# HTML 파일로 저장 및 출력\n",
        "net.save_graph(\"aml_detection_result.html\")\n",
        "print(\"시각화 완료: 'aml_detection_result.html' 파일을 확인하세요.\")"
      ],
      "metadata": {
        "id": "yOMlwqRiT0w-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176206f9-d44d-4a85-ba4d-18ebbea94abf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시각화 완료: 'aml_detection_result.html' 파일을 확인하세요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "42RBLX4hT0ri"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yIhVfAMqUuvN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-GDDeAMTzjo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anti Money Laundering Detection with GNN node classification\n",
        "This notenook includes GNN model training and dataset implementation with PyG library. In this example, we used HI-Small_Trans.csv as our dataset for training and testing."
      ],
      "metadata": {
        "id": "tGTX0pb17dcf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ep6dfLSU7V9V"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "from typing import Callable, Optional\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch_geometric.data import (\n",
        "    Data,\n",
        "    InMemoryDataset\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data visualization and possible feature engineering\n",
        "Let's look into the dataset"
      ],
      "metadata": {
        "id": "hjqJin3D7h8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "5OgmMxSf7aRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a03bb9-9ae1-406b-b6bf-841b18167f0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "0  2022/09/01 00:17         20  800104D70       20  800104D70   \n",
            "1  2022/09/01 00:02       3196  800107150     3196  800107150   \n",
            "2  2022/09/01 00:17       1208  80010E430     1208  80010E430   \n",
            "3  2022/09/01 00:03       1208  80010E650       20  80010E6F0   \n",
            "4  2022/09/01 00:02       1208  80010E650       20  80010EA30   \n",
            "\n",
            "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "0          6794.63          US Dollar      6794.63        US Dollar   \n",
            "1          7739.29          US Dollar      7739.29        US Dollar   \n",
            "2          1880.23          US Dollar      1880.23        US Dollar   \n",
            "3      73966883.00          US Dollar  73966883.00        US Dollar   \n",
            "4      45868454.00          US Dollar  45868454.00        US Dollar   \n",
            "\n",
            "  Payment Format  Is Laundering  \n",
            "0   Reinvestment              0  \n",
            "1   Reinvestment              0  \n",
            "2   Reinvestment              0  \n",
            "3         Cheque              0  \n",
            "4         Cheque              0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the viewing the dataframe, we suggest that we can extract all accounts from receiver and payer among all transcation for sorting the suspicious accounts. We can transform the whole dataset into node classification problem by considering accounts as nodes while transcation as edges.\n",
        "\n",
        "The object columns should be encoded into classes with sklearn LabelEncoder."
      ],
      "metadata": {
        "id": "4lTYv0_n7qiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "vpGx-usM7tQB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3b864a-1295-4920-aa91-99a56e8d1599"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp              object\n",
            "From Bank               int64\n",
            "Account                object\n",
            "To Bank                 int64\n",
            "Account.1              object\n",
            "Amount Received       float64\n",
            "Receiving Currency     object\n",
            "Amount Paid           float64\n",
            "Payment Currency       object\n",
            "Payment Format         object\n",
            "Is Laundering           int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if there are any null values"
      ],
      "metadata": {
        "id": "h4j0SxMK7vEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "OFHvt2vM7v11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89f46f7-228b-461e-9e32-090bb968001c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp             0\n",
            "From Bank             0\n",
            "Account               0\n",
            "To Bank               0\n",
            "Account.1             0\n",
            "Amount Received       0\n",
            "Receiving Currency    0\n",
            "Amount Paid           0\n",
            "Payment Currency      0\n",
            "Payment Format        0\n",
            "Is Laundering         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two columns representing paid and received amount of each transcation, wondering if it is necessary to split the amount into two columns when they shared the same value, unless there are transcation fee/transcation between different currency. Let's find out"
      ],
      "metadata": {
        "id": "g2bl3K_57x_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Amount Received equals to Amount Paid:')\n",
        "print(df['Amount Received'].equals(df['Amount Paid']))\n",
        "print('Receiving Currency equals to Payment Currency:')\n",
        "print(df['Receiving Currency'].equals(df['Payment Currency']))"
      ],
      "metadata": {
        "id": "5iOZKoLh70CM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a9ba96-492a-455b-8db6-8598454cfe38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount Received equals to Amount Paid:\n",
            "False\n",
            "Receiving Currency equals to Payment Currency:\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seens involved the transcations between different currency, let's print it out"
      ],
      "metadata": {
        "id": "R3VDxWgq72ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "not_equal1 = df.loc[~(df['Amount Received'] == df['Amount Paid'])]\n",
        "not_equal2 = df.loc[~(df['Receiving Currency'] == df['Payment Currency'])]\n",
        "print(not_equal1)\n",
        "print('---------------------------------------------------------------------------')\n",
        "print(not_equal2)"
      ],
      "metadata": {
        "id": "bWhIqSKh73fm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d72a3d7-bc7a-4552-de31-eaf50792c214"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "268    2022/09/01 00:19       4011  8032D1A00     4011  8032D1A00   \n",
            "282    2022/09/01 00:13       5991  80341B8B0     5991  80341B8B0   \n",
            "1577   2022/09/01 00:18          0  800417500        0  800417500   \n",
            "1926   2022/09/01 00:11       3504  800492D00     3504  800492D00   \n",
            "5721   2022/09/01 00:29       1488  800C948C0     1488  800C948C0   \n",
            "6071   2022/09/01 00:17       2597  800DD7610     2597  800DD7610   \n",
            "15773  2022/09/01 00:29       1818  8021F4AE0     1818  8021F4AE0   \n",
            "16371  2022/09/01 00:05       1601  802321380     1601  802321380   \n",
            "21135  2022/09/01 00:05      34384  802B553D0    34384  802B553D0   \n",
            "23296  2022/09/01 00:20        867  802EAE130      867  802EAE130   \n",
            "28907  2022/09/01 00:06       5763  8037A4C20     5763  8037A4C20   \n",
            "30171  2022/09/01 00:11       1922  8039627F0     1922  8039627F0   \n",
            "32009  2022/09/01 00:24       3902  803C0AB30     3902  803C0AB30   \n",
            "32587  2022/09/01 00:27       9043  803CF1BF0     9043  803CF1BF0   \n",
            "32792  2022/09/01 00:19      24528  803D2E6D0    24528  803D2E6D0   \n",
            "33351  2022/09/01 00:05      18170  803DD9960    18170  803DD9960   \n",
            "35078  2022/09/01 00:12      25444  804104E60    25444  804104E60   \n",
            "35821  2022/09/01 00:25       2954  8041E1FF0     2954  8041E1FF0   \n",
            "35866  2022/09/01 00:09        741  8041E82F0      741  8041E82F0   \n",
            "37835  2022/09/01 00:26       4292  8045079F0     4292  8045079F0   \n",
            "38711  2022/09/01 00:03      25642  804678E50    25642  804678E50   \n",
            "42824  2022/09/01 00:18      18024  804FE4CD0    18024  804FE4CD0   \n",
            "44371  2022/09/01 00:22     111247  8051FBFC0   111247  8051FBFC0   \n",
            "47668  2022/09/01 00:12      24528  8056AA2F0    24528  8056AA2F0   \n",
            "48233  2022/09/01 00:14       3327  80575FAB0     3327  80575FAB0   \n",
            "49687  2022/09/01 00:08      19596  8059898E0    19596  8059898E0   \n",
            "\n",
            "       Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "268              97.27               Euro       113.98        US Dollar   \n",
            "282              14.26           UK Pound        18.42        US Dollar   \n",
            "1577             42.41               Euro        49.69        US Dollar   \n",
            "1926           6707.83          US Dollar      5724.46             Euro   \n",
            "5721             42.71               Euro        50.05        US Dollar   \n",
            "6071              7.94               Euro         9.31        US Dollar   \n",
            "15773            19.55               Euro        22.91        US Dollar   \n",
            "16371            59.26               Euro        69.44        US Dollar   \n",
            "21135             0.01          US Dollar         0.08             Yuan   \n",
            "23296            47.56           UK Pound        61.43        US Dollar   \n",
            "28907           206.06               Yuan        30.77        US Dollar   \n",
            "30171             7.35               Euro         8.61        US Dollar   \n",
            "32009             7.49               Euro         8.77        US Dollar   \n",
            "32587            12.94               Euro        15.16        US Dollar   \n",
            "32792            17.50    Canadian Dollar        13.26        US Dollar   \n",
            "33351             9.05           UK Pound        11.70        US Dollar   \n",
            "35078           193.45               Euro       226.68        US Dollar   \n",
            "35821          3270.57              Rupee        44.53        US Dollar   \n",
            "35866            15.72           UK Pound        20.31        US Dollar   \n",
            "37835             4.56  Australian Dollar         3.23        US Dollar   \n",
            "38711            12.39               Euro        14.52        US Dollar   \n",
            "42824           807.04               Yuan       120.50        US Dollar   \n",
            "44371          3312.96              Ruble        42.58        US Dollar   \n",
            "47668           609.03             Shekel       180.35        US Dollar   \n",
            "48233          1980.03          US Dollar      1689.76             Euro   \n",
            "49687            31.77               Euro        37.22        US Dollar   \n",
            "\n",
            "      Payment Format  Is Laundering  \n",
            "268              ACH              0  \n",
            "282              ACH              0  \n",
            "1577             ACH              0  \n",
            "1926             ACH              0  \n",
            "5721             ACH              0  \n",
            "6071             ACH              0  \n",
            "15773            ACH              0  \n",
            "16371            ACH              0  \n",
            "21135            ACH              0  \n",
            "23296            ACH              0  \n",
            "28907            ACH              0  \n",
            "30171            ACH              0  \n",
            "32009            ACH              0  \n",
            "32587            ACH              0  \n",
            "32792            ACH              0  \n",
            "33351            ACH              0  \n",
            "35078            ACH              0  \n",
            "35821            ACH              0  \n",
            "35866            ACH              0  \n",
            "37835            ACH              0  \n",
            "38711            ACH              0  \n",
            "42824            ACH              0  \n",
            "44371            ACH              0  \n",
            "47668            ACH              0  \n",
            "48233            ACH              0  \n",
            "49687            ACH              0  \n",
            "---------------------------------------------------------------------------\n",
            "              Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "268    2022/09/01 00:19       4011  8032D1A00     4011  8032D1A00   \n",
            "282    2022/09/01 00:13       5991  80341B8B0     5991  80341B8B0   \n",
            "1577   2022/09/01 00:18          0  800417500        0  800417500   \n",
            "1926   2022/09/01 00:11       3504  800492D00     3504  800492D00   \n",
            "5721   2022/09/01 00:29       1488  800C948C0     1488  800C948C0   \n",
            "6071   2022/09/01 00:17       2597  800DD7610     2597  800DD7610   \n",
            "15773  2022/09/01 00:29       1818  8021F4AE0     1818  8021F4AE0   \n",
            "16371  2022/09/01 00:05       1601  802321380     1601  802321380   \n",
            "21135  2022/09/01 00:05      34384  802B553D0    34384  802B553D0   \n",
            "23296  2022/09/01 00:20        867  802EAE130      867  802EAE130   \n",
            "28907  2022/09/01 00:06       5763  8037A4C20     5763  8037A4C20   \n",
            "30171  2022/09/01 00:11       1922  8039627F0     1922  8039627F0   \n",
            "32009  2022/09/01 00:24       3902  803C0AB30     3902  803C0AB30   \n",
            "32587  2022/09/01 00:27       9043  803CF1BF0     9043  803CF1BF0   \n",
            "32792  2022/09/01 00:19      24528  803D2E6D0    24528  803D2E6D0   \n",
            "33351  2022/09/01 00:05      18170  803DD9960    18170  803DD9960   \n",
            "35078  2022/09/01 00:12      25444  804104E60    25444  804104E60   \n",
            "35821  2022/09/01 00:25       2954  8041E1FF0     2954  8041E1FF0   \n",
            "35866  2022/09/01 00:09        741  8041E82F0      741  8041E82F0   \n",
            "37835  2022/09/01 00:26       4292  8045079F0     4292  8045079F0   \n",
            "38711  2022/09/01 00:03      25642  804678E50    25642  804678E50   \n",
            "42824  2022/09/01 00:18      18024  804FE4CD0    18024  804FE4CD0   \n",
            "44371  2022/09/01 00:22     111247  8051FBFC0   111247  8051FBFC0   \n",
            "47668  2022/09/01 00:12      24528  8056AA2F0    24528  8056AA2F0   \n",
            "48233  2022/09/01 00:14       3327  80575FAB0     3327  80575FAB0   \n",
            "49687  2022/09/01 00:08      19596  8059898E0    19596  8059898E0   \n",
            "\n",
            "       Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "268              97.27               Euro       113.98        US Dollar   \n",
            "282              14.26           UK Pound        18.42        US Dollar   \n",
            "1577             42.41               Euro        49.69        US Dollar   \n",
            "1926           6707.83          US Dollar      5724.46             Euro   \n",
            "5721             42.71               Euro        50.05        US Dollar   \n",
            "6071              7.94               Euro         9.31        US Dollar   \n",
            "15773            19.55               Euro        22.91        US Dollar   \n",
            "16371            59.26               Euro        69.44        US Dollar   \n",
            "21135             0.01          US Dollar         0.08             Yuan   \n",
            "23296            47.56           UK Pound        61.43        US Dollar   \n",
            "28907           206.06               Yuan        30.77        US Dollar   \n",
            "30171             7.35               Euro         8.61        US Dollar   \n",
            "32009             7.49               Euro         8.77        US Dollar   \n",
            "32587            12.94               Euro        15.16        US Dollar   \n",
            "32792            17.50    Canadian Dollar        13.26        US Dollar   \n",
            "33351             9.05           UK Pound        11.70        US Dollar   \n",
            "35078           193.45               Euro       226.68        US Dollar   \n",
            "35821          3270.57              Rupee        44.53        US Dollar   \n",
            "35866            15.72           UK Pound        20.31        US Dollar   \n",
            "37835             4.56  Australian Dollar         3.23        US Dollar   \n",
            "38711            12.39               Euro        14.52        US Dollar   \n",
            "42824           807.04               Yuan       120.50        US Dollar   \n",
            "44371          3312.96              Ruble        42.58        US Dollar   \n",
            "47668           609.03             Shekel       180.35        US Dollar   \n",
            "48233          1980.03          US Dollar      1689.76             Euro   \n",
            "49687            31.77               Euro        37.22        US Dollar   \n",
            "\n",
            "      Payment Format  Is Laundering  \n",
            "268              ACH              0  \n",
            "282              ACH              0  \n",
            "1577             ACH              0  \n",
            "1926             ACH              0  \n",
            "5721             ACH              0  \n",
            "6071             ACH              0  \n",
            "15773            ACH              0  \n",
            "16371            ACH              0  \n",
            "21135            ACH              0  \n",
            "23296            ACH              0  \n",
            "28907            ACH              0  \n",
            "30171            ACH              0  \n",
            "32009            ACH              0  \n",
            "32587            ACH              0  \n",
            "32792            ACH              0  \n",
            "33351            ACH              0  \n",
            "35078            ACH              0  \n",
            "35821            ACH              0  \n",
            "35866            ACH              0  \n",
            "37835            ACH              0  \n",
            "38711            ACH              0  \n",
            "42824            ACH              0  \n",
            "44371            ACH              0  \n",
            "47668            ACH              0  \n",
            "48233            ACH              0  \n",
            "49687            ACH              0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The size of two df shows that there are transcation fee and transcation between different currency, we cannot combine/drop the amount columns.\n",
        "\n",
        "As we are going to encode the columns, we have to make sure that the classes of same attribute are aligned. Let's check if the list of Receiving Currency and Payment Currency are the same"
      ],
      "metadata": {
        "id": "AGmGCinv78ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(df['Receiving Currency'].unique()))\n",
        "print(sorted(df['Payment Currency'].unique()))"
      ],
      "metadata": {
        "id": "CWIbiHr879_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee0d786-3831-420e-d7a6-0791df98c8c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Australian Dollar', 'Bitcoin', 'Canadian Dollar', 'Euro', 'Ruble', 'Rupee', 'Shekel', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n",
            "['Australian Dollar', 'Bitcoin', 'Canadian Dollar', 'Euro', 'Ruble', 'Rupee', 'Shekel', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "We will show the functions used in the PyG dataset first, dataset and model training will be provided in bottom section\n",
        "In the data preprocessing, we perform below transformation:\n",
        "\n",
        "1. Transform the Timestamp with min max normalization.\n",
        "2. Create unique ID for each account by adding bank code with account number.\n",
        "3. Create receiving_df with the information of receiving accounts, received amount and currency\n",
        "4. Create paying_df with the information of payer accounts, paid amount and currency\n",
        "5. Create a list of currency used among all transactions\n",
        "6. Label the 'Payment Format', 'Payment Currency', 'Receiving Currency' by classes with sklearn LabelEncoder"
      ],
      "metadata": {
        "id": "Qjtox-zr7_W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_label_encoder(df, columns):\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        for i in columns:\n",
        "            df[i] = le.fit_transform(df[i].astype(str))\n",
        "        return df\n",
        "\n",
        "def preprocess(df):\n",
        "        df = df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
        "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
        "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
        "\n",
        "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
        "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
        "        df = df.sort_values(by=['Account'])\n",
        "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
        "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
        "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
        "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
        "\n",
        "        return df, receiving_df, paying_df, currency_ls"
      ],
      "metadata": {
        "id": "MfUZLkjX8MaY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look of processed df"
      ],
      "metadata": {
        "id": "Vf4k6tPy8NfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df, receiving_df, paying_df, currency_ls = preprocess(df = df)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "AL1LuBSF8Own",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfaabd72-e581-4559-8fd2-68b69fd527f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Timestamp  From Bank      Account  To Bank        Account.1  \\\n",
            "470   0.103448          0  0_8000474C0        0      0_8000474C0   \n",
            "471   0.551724          0  0_800047930        0      0_800047930   \n",
            "295   0.482759          0  0_80006C140    27453  27453_80345B620   \n",
            "474   0.413793          0  0_80006C140        0      0_80006C140   \n",
            "473   0.000000          0  0_80006DFE0        0      0_80006DFE0   \n",
            "\n",
            "     Amount Received  Receiving Currency  Amount Paid  Payment Currency  \\\n",
            "470            11.21                   8        11.21                 8   \n",
            "471        169390.13                   8    169390.13                 8   \n",
            "295         50000.00                   8     50000.00                 8   \n",
            "474            23.48                   8        23.48                 8   \n",
            "473            19.18                   8        19.18                 8   \n",
            "\n",
            "     Payment Format  Is Laundering  \n",
            "470               5              0  \n",
            "471               5              0  \n",
            "295               0              0  \n",
            "474               5              0  \n",
            "473               5              0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "paying df and receiving df:"
      ],
      "metadata": {
        "id": "Guiuhc5v8QHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(receiving_df.head())\n",
        "print(paying_df.head())"
      ],
      "metadata": {
        "id": "g1wGA8Fz8RPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8397e346-bf73-48ba-9e7c-2c4142cd5247"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Account  Amount Received  Receiving Currency\n",
            "470      0_8000474C0            11.21                   8\n",
            "471      0_800047930        169390.13                   8\n",
            "295  27453_80345B620         50000.00                   8\n",
            "474      0_80006C140            23.48                   8\n",
            "473      0_80006DFE0            19.18                   8\n",
            "         Account  Amount Paid  Payment Currency\n",
            "470  0_8000474C0        11.21                 8\n",
            "471  0_800047930    169390.13                 8\n",
            "295  0_80006C140     50000.00                 8\n",
            "474  0_80006C140        23.48                 8\n",
            "473  0_80006DFE0        19.18                 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "currency_ls:"
      ],
      "metadata": {
        "id": "92Gilm-u8Swf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(currency_ls)"
      ],
      "metadata": {
        "id": "HOIBCHCB8TpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95435761-ee3d-4703-e813-90412b8eb58f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would like to extract all unique accounts from payer and receiver as node of our graph. It includes the unique account ID, Bank code and the label of 'Is Laundering'.\n",
        "In this section, we consider both payer and receiver involved in a illicit transaction as suspicious accounts, we will label both accounts with 'Is Laundering' == 1."
      ],
      "metadata": {
        "id": "29NyA-Id8Vmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_account(df):\n",
        "        ldf = df[['Account', 'From Bank']]\n",
        "        rdf = df[['Account.1', 'To Bank']]\n",
        "        suspicious = df[df['Is Laundering']==1]\n",
        "        s1 = suspicious[['Account', 'Is Laundering']]\n",
        "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
        "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
        "        suspicious = pd.concat([s1, s2], join='outer')\n",
        "        suspicious = suspicious.drop_duplicates()\n",
        "\n",
        "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
        "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
        "        df = pd.concat([ldf, rdf], join='outer')\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "        df['Is Laundering'] = 0\n",
        "        df.set_index('Account', inplace=True)\n",
        "        df.update(suspicious.set_index('Account'))\n",
        "        df = df.reset_index()\n",
        "        return df"
      ],
      "metadata": {
        "id": "VBsoMWwn8U9y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look of the account list:"
      ],
      "metadata": {
        "id": "CxAzvL_W8ZTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accounts = get_all_account(df)\n",
        "print(accounts.head())"
      ],
      "metadata": {
        "id": "dcVxbhIt8YnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb6ec00-13fd-4a93-ddd4-0e89c49fcb35"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Account  Bank  Is Laundering\n",
            "0  0_8000474C0     0              0\n",
            "1  0_800047930     0              0\n",
            "2  0_80006C140     0              0\n",
            "3  0_80006DFE0     0              0\n",
            "4  0_80006F150     0              0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node features\n",
        "For node features, we would like to aggregate the mean of paid and received amount with different types of currency as the new features of each node."
      ],
      "metadata": {
        "id": "M5b6xPBw8bi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def paid_currency_aggregate(currency_ls, paying_df, accounts):\n",
        "        for i in currency_ls:\n",
        "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
        "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
        "        return accounts\n",
        "\n",
        "def received_currency_aggregate(currency_ls, receiving_df, accounts):\n",
        "    for i in currency_ls:\n",
        "        temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
        "        accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
        "    accounts = accounts.fillna(0)\n",
        "    return accounts"
      ],
      "metadata": {
        "id": "BYMjpsNZ8eE1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can define the node attributes by the bank code and the mean of paid and received amount with different types of currency."
      ],
      "metadata": {
        "id": "WHdHJOLg8fOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_node_attr(currency_ls, paying_df,receiving_df, accounts):\n",
        "        node_df = paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
        "        node_df = received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
        "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
        "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
        "        node_df = df_label_encoder(node_df,['Bank'])\n",
        "#         node_df = torch.from_numpy(node_df.values).to(torch.float)  # comment for visualization\n",
        "        return node_df, node_label"
      ],
      "metadata": {
        "id": "vJIAN0DS8gSH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look of node_df:"
      ],
      "metadata": {
        "id": "37I2o3Vp8iFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_df, node_label = get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
        "print(node_df.head())"
      ],
      "metadata": {
        "id": "ZeGJ5VF68jAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2912ab34-7d79-4923-9e85-080968f1cb8d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Bank  avg paid 0  avg paid 1  avg paid 2  avg paid 3  avg paid 4  \\\n",
            "0     0         0.0         0.0         0.0         0.0         0.0   \n",
            "1     0         0.0         0.0         0.0         0.0         0.0   \n",
            "2     0         0.0         0.0         0.0         0.0         0.0   \n",
            "3     0         0.0         0.0         0.0         0.0         0.0   \n",
            "4     0         0.0         0.0         0.0         0.0         0.0   \n",
            "\n",
            "   avg paid 5  avg paid 6  avg paid 7    avg paid 8  avg paid 9  avg paid 10  \\\n",
            "0         0.0         0.0         0.0  6.794630e+03         0.0          0.0   \n",
            "1         0.0         0.0         0.0  7.739290e+03         0.0          0.0   \n",
            "2         0.0         0.0         0.0  9.439450e+02         0.0          0.0   \n",
            "3         0.0         0.0         0.0  3.994511e+07         0.0          0.0   \n",
            "4         0.0         0.0         0.0  3.994511e+07         0.0          0.0   \n",
            "\n",
            "   avg received 0  avg received 1  avg received 2  avg received 3  \\\n",
            "0             0.0             0.0             0.0             0.0   \n",
            "1             0.0             0.0             0.0             0.0   \n",
            "2             0.0             0.0             0.0             0.0   \n",
            "3             0.0             0.0             0.0             0.0   \n",
            "4             0.0             0.0             0.0             0.0   \n",
            "\n",
            "   avg received 4  avg received 5  avg received 6  avg received 7  \\\n",
            "0             0.0             0.0             0.0             0.0   \n",
            "1             0.0             0.0             0.0             0.0   \n",
            "2             0.0             0.0             0.0             0.0   \n",
            "3             0.0             0.0             0.0             0.0   \n",
            "4             0.0             0.0             0.0             0.0   \n",
            "\n",
            "   avg received 8  avg received 9  avg received 10  \n",
            "0    6.794630e+03             0.0              0.0  \n",
            "1    7.739290e+03             0.0              0.0  \n",
            "2    9.439450e+02             0.0              0.0  \n",
            "3    7.396688e+07             0.0              0.0  \n",
            "4    4.586845e+07             0.0              0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edge features\n",
        "In terms of edge features, we would like to conside each transcation as edges.\n",
        "For edge index, we replace all account with index and stack into a list with size of [2, num of transcation]\n",
        "For edge attributes, we used 'Timestamp', 'Amount Received', 'Receiving Currency', 'Amount Paid', 'Payment Currency' and 'Payment Format'"
      ],
      "metadata": {
        "id": "trpZySDa8kdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_edge_df(accounts, df):\n",
        "        accounts = accounts.reset_index(drop=True)\n",
        "        accounts['ID'] = accounts.index\n",
        "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
        "        df['From'] = df['Account'].map(mapping_dict)\n",
        "        df['To'] = df['Account.1'].map(mapping_dict)\n",
        "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
        "\n",
        "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
        "\n",
        "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
        "\n",
        "#         edge_attr = torch.from_numpy(df.values).to(torch.float)  # comment for visualization\n",
        "\n",
        "        edge_attr = df  # for visualization\n",
        "        return edge_attr, edge_index"
      ],
      "metadata": {
        "id": "tAcc7vsr8msE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "edge_attr:"
      ],
      "metadata": {
        "id": "Ntiu3Ufl8nqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edge_attr, edge_index = get_edge_df(accounts, df)\n",
        "print(edge_attr.head())"
      ],
      "metadata": {
        "id": "uSRfZOTf8orX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21766e9-f9a1-48ce-bdff-7abec713df5c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Timestamp  Amount Received  Receiving Currency  Amount Paid  \\\n",
            "470   0.103448            11.21                   8        11.21   \n",
            "471   0.551724        169390.13                   8    169390.13   \n",
            "295   0.482759         50000.00                   8     50000.00   \n",
            "474   0.413793            23.48                   8        23.48   \n",
            "473   0.000000            19.18                   8        19.18   \n",
            "\n",
            "     Payment Currency  Payment Format  \n",
            "470                 8               5  \n",
            "471                 8               5  \n",
            "295                 8               0  \n",
            "474                 8               5  \n",
            "473                 8               5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "edge_index:"
      ],
      "metadata": {
        "id": "jmKCxThG8pva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(edge_index)"
      ],
      "metadata": {
        "id": "Dv_TbpE48qxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51943378-0371-4791-f222-18b793e622b2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,  ..., 37365, 37366, 37367],\n",
            "        [    0,     1, 22292,  ..., 37365, 37366, 37367]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final code\n",
        "Below we will show the final code for model.py, train.py and dataset.py\n",
        "# Model Architecture\n",
        "In this section, we used Graph Attention Networks as our backbone model.\n",
        "The model built with two GATConv layers followed by a linear layer with sigmoid outout for classification"
      ],
      "metadata": {
        "id": "xWQ16jmQ8tVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GATConv, Linear\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n",
        "        self.conv2 = GATConv(hidden_channels * heads, int(hidden_channels/4), heads=1, concat=False, dropout=0.6)\n",
        "        self.lin = Linear(int(hidden_channels/4), out_channels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
        "        x = self.lin(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "k8XjQVLT8vIl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyG InMemoryDataset\n",
        "Finally we can build the dataset with above functions"
      ],
      "metadata": {
        "id": "FyJ320Et8yjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AMLtoGraph(InMemoryDataset):\n",
        "\n",
        "    def __init__(self, root: str, edge_window_size: int = 10,\n",
        "                 transform: Optional[Callable] = None,\n",
        "                 pre_transform: Optional[Callable] = None):\n",
        "        self.edge_window_size = edge_window_size\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self) -> str:\n",
        "        return 'HI-Medium_Trans.csv'\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self) -> str:\n",
        "        return 'data.pt'\n",
        "\n",
        "    @property\n",
        "    def num_nodes(self) -> int:\n",
        "        return self._data.edge_index.max().item() + 1\n",
        "\n",
        "    def df_label_encoder(self, df, columns):\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        for i in columns:\n",
        "            df[i] = le.fit_transform(df[i].astype(str))\n",
        "        return df\n",
        "\n",
        "\n",
        "    def preprocess(self, df):\n",
        "        df = self.df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
        "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
        "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
        "\n",
        "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
        "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
        "        df = df.sort_values(by=['Account'])\n",
        "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
        "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
        "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
        "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
        "\n",
        "        return df, receiving_df, paying_df, currency_ls\n",
        "\n",
        "    def get_all_account(self, df):\n",
        "        ldf = df[['Account', 'From Bank']]\n",
        "        rdf = df[['Account.1', 'To Bank']]\n",
        "        suspicious = df[df['Is Laundering']==1]\n",
        "        s1 = suspicious[['Account', 'Is Laundering']]\n",
        "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
        "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
        "        suspicious = pd.concat([s1, s2], join='outer')\n",
        "        suspicious = suspicious.drop_duplicates()\n",
        "\n",
        "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
        "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
        "        df = pd.concat([ldf, rdf], join='outer')\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "        df['Is Laundering'] = 0\n",
        "        df.set_index('Account', inplace=True)\n",
        "        df.update(suspicious.set_index('Account'))\n",
        "        df = df.reset_index()\n",
        "        return df\n",
        "\n",
        "    def paid_currency_aggregate(self, currency_ls, paying_df, accounts):\n",
        "        for i in currency_ls:\n",
        "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
        "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
        "        return accounts\n",
        "\n",
        "    def received_currency_aggregate(self, currency_ls, receiving_df, accounts):\n",
        "        for i in currency_ls:\n",
        "            temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
        "            accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
        "        accounts = accounts.fillna(0)\n",
        "        return accounts\n",
        "\n",
        "    def get_edge_df(self, accounts, df):\n",
        "        accounts = accounts.reset_index(drop=True)\n",
        "        accounts['ID'] = accounts.index\n",
        "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
        "        df['From'] = df['Account'].map(mapping_dict)\n",
        "        df['To'] = df['Account.1'].map(mapping_dict)\n",
        "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
        "\n",
        "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
        "\n",
        "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
        "\n",
        "        edge_attr = torch.from_numpy(df.values).to(torch.float)\n",
        "        return edge_attr, edge_index\n",
        "\n",
        "    def get_node_attr(self, currency_ls, paying_df,receiving_df, accounts):\n",
        "        node_df = self.paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
        "        node_df = self.received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
        "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
        "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
        "        node_df = self.df_label_encoder(node_df,['Bank'])\n",
        "        node_df = torch.from_numpy(node_df.values).to(torch.float)\n",
        "        return node_df, node_label\n",
        "\n",
        "    def process(self):\n",
        "        df = pd.read_csv(self.raw_paths[0])\n",
        "        df, receiving_df, paying_df, currency_ls = self.preprocess(df)\n",
        "        accounts = self.get_all_account(df)\n",
        "        node_attr, node_label = self.get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
        "        edge_attr, edge_index = self.get_edge_df(accounts, df)\n",
        "\n",
        "        data = Data(x=node_attr,\n",
        "                    edge_index=edge_index,\n",
        "                    y=node_label,\n",
        "                    edge_attr=edge_attr\n",
        "                    )\n",
        "\n",
        "        data_list = [data]\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [d for d in data_list if self.pre_filter(d)]\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(d) for d in data_list]\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])"
      ],
      "metadata": {
        "id": "vPu7O0_f83Ku"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "As we cannot create folder in kaggle, please follow the instructions in https://github.com/issacchan26/AntiMoneyLaunderingDetectionWithGNN before you start training"
      ],
      "metadata": {
        "id": "Zsu6hmHN85Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "import os\n",
        "root_path = os.path.dirname(trans_path)\n",
        "dataset = AMLtoGraph(root_path)\n",
        "data = dataset[0]\n",
        "epoch = 20\n",
        "\n",
        "model = GAT(in_channels=data.num_features, hidden_channels=16, out_channels=1, heads=8)\n",
        "model = model.to(device)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "\n",
        "split = T.RandomNodeSplit(split='train_rest', num_val=0.1, num_test=0)\n",
        "data = split(data)\n",
        "\n",
        "train_loader = loader = NeighborLoader(\n",
        "    data,\n",
        "    num_neighbors=[30] * 2,\n",
        "    batch_size=256,\n",
        "    input_nodes=data.train_mask,\n",
        ")\n",
        "\n",
        "test_loader = loader = NeighborLoader(\n",
        "    data,\n",
        "    num_neighbors=[30] * 2,\n",
        "    batch_size=256,\n",
        "    input_nodes=data.val_mask,\n",
        ")\n",
        "\n",
        "for i in range(epoch):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        data.to(device)\n",
        "        pred = model(data.x, data.edge_index, data.edge_attr)\n",
        "        ground_truth = data.y\n",
        "        loss = criterion(pred, ground_truth.unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss)\n",
        "    if epoch%10 == 0:\n",
        "        print(f\"Epoch: {i:03d}, Loss: {total_loss:.4f}\")\n",
        "        model.eval()\n",
        "        acc = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for test_data in test_loader:\n",
        "                test_data.to(device)\n",
        "                pred = model(test_data.x, test_data.edge_index, test_data.edge_attr)\n",
        "                ground_truth = test_data.y\n",
        "                correct = (pred == ground_truth.unsqueeze(1)).sum().item()\n",
        "                total += len(ground_truth)\n",
        "                acc += correct\n",
        "            acc = acc/total\n",
        "            print('accuracy:', acc)"
      ],
      "metadata": {
        "id": "Wxo7lPTB87wD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d9cfe8-4ee0-4f0d-f60a-66bc4ae69ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Future Work\n",
        "In this notebook, we performed the node classification with GAT and the result accuracy looks satisfied.\n",
        "However, it may due to highly imbalance data of the dataset. It is suggested that balance the class of 1 and 0 in the data preprocessing. It is expected that the accuracy will dropped a little bit after balancing the data. We will keep exploring to see if there are any other models give better performance, such as other traditional regression/classifier model."
      ],
      "metadata": {
        "id": "VM8PrYhN89Z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "Some of the feature engineering of this repo are referenced to below papers, highly recommend to read:\n",
        "\n",
        "1. Weber, M., Domeniconi, G., Chen, J., Weidele, D. K. I., Bellei, C., Robinson, T., & Leiserson, C. E. (2019). Anti-money laundering in bitcoin: Experimenting with graph convolutional networks for financial forensics. arXiv preprint arXiv:1908.02591.\n",
        "2. Johannessen, F., & Jullum, M. (2023). Finding Money Launderers Using Heterogeneous Graph Neural Networks. arXiv preprint arXiv:2307.13499."
      ],
      "metadata": {
        "id": "SQc7Y1nR8_gj"
      }
    }
  ]
}